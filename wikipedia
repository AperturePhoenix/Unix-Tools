#!/bin/bash
TITLE=$1

#Make a directory for downloading webpages, log file, and path file
#Path file contains the list of pages the program traversed to reach Philosophy
mkdir -p output
cd output
rm path

while [ $TITLE != "Philosophy" ]
do
    echo $TITLE
    echo $TITLE >> path
    LINK=`cat path | egrep -o "^$TITLE$" | wc -l`
    wget -nc https://en.wikipedia.org/wiki/$TITLE &>> log

    #Get the link for the next article
    FILENAME=`cat $TITLE | tr -d '\r\n' | sed 's/<p>/\n&/g' | sed 's/([^)]*href[^)]*)//g' | sed 's/<li>.*<\/li>//g' | sed 's/<small>.*<\/small>//g' | tail -n +2 > temp`
    LINE=`cat temp | egrep -n '<b>' | head -n 1 | egrep -o '^[0-9]*'`
    FILENAME=`cat temp | tail -n +$LINE | egrep -o 'href="[^"]*"' | egrep -v '[#:]' | tail -n +$LINK | head -n 1 | sed 's/.*\/.*\/\(.*\)"/\1/'`
    TITLE=$FILENAME
    sleep 1
done

echo 'Philosophy'
LINKS=`cat path | wc -l`
echo "$LINKS clicks away from Philosophy"
